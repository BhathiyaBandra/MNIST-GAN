{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tdom1vVfyFBX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yogYuXWzyFBY",
        "outputId": "d06c3a37-052a-4589-9d12-31105deb5fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1de412ce90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Train and Test Datasets\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "\n",
        "random_seed = 1\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3tjZiQkyFBZ"
      },
      "outputs": [],
      "source": [
        "#Get MNIST dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_-spl9OyFBZ"
      },
      "outputs": [],
      "source": [
        "# Convert training data\n",
        "train_data = enumerate(train_loader)\n",
        "batch_idx, (train_data_init, train_targets_init) = next(train_data)\n",
        "\n",
        "train_data = torch.zeros((batch_size_train,28*28))\n",
        "train_targets = torch.zeros((batch_size_train,10))\n",
        "for i in range(batch_size_train):\n",
        "    train_data[i] = torch.flatten(train_data_init[i][0])\n",
        "    tmp = torch.zeros((10))\n",
        "    tmp[train_targets_init[i]] = 1.0\n",
        "    train_targets[i] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75cT9JUqyFBZ"
      },
      "outputs": [],
      "source": [
        "# Convert Testing data\n",
        "test_data = enumerate(test_loader)\n",
        "batch_idx, (test_data_init, test_targets) = next(test_data)\n",
        "test_data = torch.zeros((batch_size_test,28*28))\n",
        "\n",
        "for i in range(batch_size_test):\n",
        "    test_data[i] = torch.flatten(test_data_init[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzfhAqe9yFBg"
      },
      "outputs": [],
      "source": [
        "# MNIST Classifier\n",
        "\n",
        "class MNISTclassifier(nn.Module):\n",
        "    def __init__(self, input_size: int):\n",
        "        super(MNISTclassifier, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_size, 512, bias=True)\n",
        "        self.second_layer = nn.Linear(512, 64, bias=True)\n",
        "        self.third_layer = nn.Linear(64, 10, bias=True)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.soft = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.input_layer(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.second_layer(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.third_layer(out)\n",
        "        out = self.soft(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1I3VUHTyFBh",
        "outputId": "2b423ace-f507-4ab1-82c7-d6897d5764c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.09007976949214935 Prediction accuracy: 0.125\n",
            "Epoch: 1000 Loss: 0.0004847997333854437 Prediction accuracy: 1.0\n",
            "Epoch: 2000 Loss: 3.6593861295841634e-05 Prediction accuracy: 1.0\n",
            "Epoch: 3000 Loss: 8.225408237194642e-05 Prediction accuracy: 1.0\n",
            "Epoch: 4000 Loss: 3.867715349770151e-06 Prediction accuracy: 1.0\n",
            "Epoch: 5000 Loss: 4.8067009629448876e-05 Prediction accuracy: 1.0\n",
            "Epoch: 6000 Loss: 9.29932593862759e-06 Prediction accuracy: 1.0\n",
            "Epoch: 7000 Loss: 2.7762269382947125e-05 Prediction accuracy: 1.0\n",
            "Epoch: 8000 Loss: 1.242377294374819e-07 Prediction accuracy: 1.0\n",
            "Epoch: 9000 Loss: 8.084980436251499e-07 Prediction accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Define Hyperparameters\n",
        "learning_rate = 0.01\n",
        "number_of_iterations = 10000\n",
        "\n",
        "\n",
        "MNIST = MNISTclassifier(28*28)\n",
        "criterian = nn.MSELoss()\n",
        "optimizer = torch.optim.Adadelta(MNIST.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(number_of_iterations):\n",
        "    order = [i for i in range(batch_size_train)]\n",
        "    random.shuffle(order)\n",
        "    for i in order:\n",
        "        nn_out = MNIST(torch.flatten(train_data_init[i][0]))\n",
        "        loss = criterian(nn_out, train_targets[i].float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if epoch%(number_of_iterations/10) == 0:\n",
        "        predict_out = torch.zeros((batch_size_train))\n",
        "        for i in range(batch_size_train):\n",
        "          tmp_list = MNIST(torch.flatten(train_data_init[i][0])).tolist()\n",
        "          predict_out[i] = tmp_list.index(max(tmp_list))\n",
        "\n",
        "        predict_y=torch.round(predict_out,decimals=0).int()\n",
        "\n",
        "        print(f'Epoch: {epoch} Loss: {loss} Prediction accuracy: {accuracy_score(train_targets_init.data, predict_y.data)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXTuaC3FyFBh"
      },
      "outputs": [],
      "source": [
        "#Testing\n",
        "predict_out = torch.zeros((batch_size_test))\n",
        "\n",
        "for i in range(batch_size_test):\n",
        "    tmp_list = MNIST(torch.flatten(test_data_init[i][0])).tolist()\n",
        "    predict_out[i] = tmp_list.index(max(tmp_list))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXeB1S4XyFBi",
        "outputId": "4783b7a3-6d49-497b-da3b-dd205f8b9526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Accuracy----------------------\n",
            "prediction accuracy 0.707\n",
            "macro precision 0.7030843402571438\n",
            "micro precision 0.707\n",
            "macro recall 0.7009005336729833\n",
            "micro recall 0.707\n"
          ]
        }
      ],
      "source": [
        "print('------------Accuracy----------------------')\n",
        "predict_y=torch.round(predict_out,decimals=0).int()\n",
        "\n",
        "print('prediction accuracy',accuracy_score(test_targets.data, predict_y.data))\n",
        "\n",
        "print('macro precision',precision_score(test_targets.data, predict_y.data, average='macro'))\n",
        "print('micro precision',precision_score(test_targets.data, predict_y.data, average='micro'))\n",
        "\n",
        "print('macro recall',recall_score(test_targets.data, predict_y.data, average='macro'))\n",
        "print('micro recall',recall_score(test_targets.data, predict_y.data, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Classifier model\n",
        "torch.save(MNIST, 'C.pkl')"
      ],
      "metadata": {
        "id": "tXL5MlThBFM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.load('G.pkl')"
      ],
      "metadata": {
        "id": "NqC7wsPYHNK7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}